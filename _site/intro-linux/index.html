<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>Introduction to the Linux command-line | CTCMS Documentation and Tutorials</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="Introduction to the Linux command-line" />
<meta name="author" content="Emily Kahl" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Why you should learn Linux If you’ve never used Linux before, you might be asking “do I really need to learn this? Why can’t I just use Windows or Mac?”. The short answer is “yes”. The long answer is “yes, and that’s a good thing.”" />
<meta property="og:description" content="Why you should learn Linux If you’ve never used Linux before, you might be asking “do I really need to learn this? Why can’t I just use Windows or Mac?”. The short answer is “yes”. The long answer is “yes, and that’s a good thing.”" />
<link rel="canonical" href="https://ctcms-uq.github.io/intro-linux/" />
<meta property="og:url" content="https://ctcms-uq.github.io/intro-linux/" />
<meta property="og:site_name" content="CTCMS Documentation and Tutorials" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-15T00:00:00+10:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Introduction to the Linux command-line" />
<script type="application/ld+json">
{"dateModified":"2021-03-15T00:00:00+10:00","datePublished":"2021-03-15T00:00:00+10:00","headline":"Introduction to the Linux command-line","description":"Why you should learn Linux If you’ve never used Linux before, you might be asking “do I really need to learn this? Why can’t I just use Windows or Mac?”. The short answer is “yes”. The long answer is “yes, and that’s a good thing.”","author":{"@type":"Person","name":"Emily Kahl"},"@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://ctcms-uq.github.io/intro-linux/"},"url":"https://ctcms-uq.github.io/intro-linux/","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="https://ctcms-uq.github.io/feed.xml" title="CTCMS Documentation and Tutorials" /></head>
<body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/">CTCMS Documentation and Tutorials</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post">

  <header class="post-header">
    <h1 class="post-title">Introduction to the Linux command-line</h1>
  </header>

  <div class="post-content">
    <h2 id="why-you-should-learn-linux">Why you should learn Linux</h2>
<p>If you’ve never used Linux before, you might be asking “do I really need to learn this? Why can’t I just
use Windows or Mac?”. The short answer is “yes”. The long answer is “yes, and that’s a good thing.”</p>

<p>Linux is overwhelmingly common on scientific servers and clusters, as well as cloud computing platforms,
for both historical and technical reasons. While it’s technically possible to run use a graphical 
interface to connect with clusters over the network, it takes a lot of network bandwidth and processing
power, so it’s not feasible for clusters with more than a few users. Instead, we must use the command
line, which comes with the added bonus of allowing us to automate common, repetitive tasks (such as data
analysis pipelines or programs with complicated sets of parameters).</p>

<p>Even if you never use Linux on your personal computer or workstation, learning to efficiently
utilise the command line can still make your workflow much faster and easier in the long-run. If you’re
a Windows user, a lot of the logic will transfer to Windows Powershell even though the individual
commands will differ. And if you’re a Mac user, most of this guide will transfer to the Mac command line
basically as-is (macOS is secretly a Unix operating system).</p>

<p>Finally, Linux command line skills are highly valued in the private sector, should you choose to take
that route in the future. Almost all cloud computing and data analysis platforms use Linux “under the
hood”, and many modern machine learning tools are made with Linux in mind.</p>

<p>All of this means you’re almost guaranteed to need to use the Linux command line at <em>some</em> point in the 
future. But don’t despair! You don’t need to learn very much to get started, and everything else can be
picked up as you go. Consequently, this guide is not intended to be complete or comprehensive; it’s
more of a crash-course, covering just enough to get you up and running and producing results. I have
provided a list of further resources for more advanced topics not covered in this guide.</p>

<h2 id="terminology">Terminology</h2>
<p>Below are some useful definitions and terminology which will appear throughout this guide:</p>

<ul>
  <li><em>Shell</em>: a program that lets us give commands to a computer and receive output. It is also 
referred to as the terminal, terminal emulator or command line.</li>
  <li><em>Bash</em>: the most commonly used shell program on Linux and Mac systems. <em>Bash</em> can also refer to the
specific <em>language</em> used to issue commands to the bash <em>shell</em>.</li>
  <li><em>Flag</em>: optional parameter which can be passed to a command-line program to change its behaviour.
Flags usually take the form of one or two consecutive <code class="language-plaintext highlighter-rouge">-</code> characters, followed by a letter or a word:
e.g. <code class="language-plaintext highlighter-rouge">--help</code> or <code class="language-plaintext highlighter-rouge">-i</code>. Multiple single-letter flags can be combined together into a single option to
save on typing, e.g. <code class="language-plaintext highlighter-rouge">ls -l -a</code> can be shortened to <code class="language-plaintext highlighter-rouge">ls -la</code>.</li>
  <li><em>SSH</em>: stands for <em>secure shell</em>. Program used to connect and login to a remote, network connected
computer (such as a HPC cluster).</li>
  <li><em>Operating system</em>: software such as Windows, macOS or Linux which underpins the operation of a
computer. Manages software interfacing with the computer’s hardware, and handles starting and
scheduling user programs.</li>
  <li><em>Unix</em>: a family of operating systems with similar design and functionality. Linux and macOS are both
Unix systems.</li>
  <li><em>File system</em>: program which manages the storage, retrieval and organisation of data (files) on disk.</li>
  <li><em>Directory</em>: An abstraction which allows for multiple files to be grouped together in a single
“location”. Often also referred to as a <em>folder</em>.</li>
  <li><em>Cluster</em>: a computer system consisting of multiple smaller, tightly interlinked computers, which are 
capable coordinating to carry out large, computationally intensive calculations in parallel. Often 
referred to as a supercomputer.</li>
  <li><em>Node</em>: a singular, self-contained computer, many instances of which are interlinked to form a 
cluster. A cluster may contain several different types of nodes, such as nodes with large amounts of
RAM or attached GPUs.</li>
  <li><em>Login node</em>: a special type of node which serves as the gateway of a cluster. Users SSH into the
login node, which then provides (managed) access to the rest of the cluster.</li>
</ul>

<p>Throughout this guide I will demonstrate the syntax of commands through the use of <em>dummy arguments</em> -
placeholder names which you will need to replace with the actual file, path or argument when running the
command. Dummy arguments are denoted by being enclosed in angle brackets (“&lt;” and &gt;”), so <code class="language-plaintext highlighter-rouge">get &lt;file&gt;</code>
doesn’t mean you should literally type “get &lt;file&gt;”, but rather that you would substitute the name of
the target file, to get something like <code class="language-plaintext highlighter-rouge">get output.txt</code>.</p>

<h2 id="setup-and-required-software">Setup and required software</h2>
<p>If you already use Mac or Linux (e.g. Ubuntu), then you’re all set: everything you need to follow this
tutorial should already be installed on your computer. If something you need isn’t installed, it will be
available on the App store (for Mac) or your Linux distribution’s package manager (e.g the Software
Center in Ubuntu).</p>

<p>If you’re using Windows, you’ll need to install some programs before you can get started. First, you’ll 
need a program which can execute Linux command-line programs. There are three main programs which can do
this on Windows:</p>

<ul>
  <li><a href="https://www.cygwin.com/">Cygwin</a>: a standalone programming environment which includes a terminal
emulator and lots of Linux command-line utilities. Cygwin is very easy to install and will include
most utilities you’ll need.</li>
  <li><a href="https://gitforwindows.org/">Git for Windows</a>: similar to Cygwin, but focused on source code
management. Software Carpentry has a <a href="https://carpentries.github.io/workshop-template/#shell">video
tutorial</a> detailing how to install and setup
Git for Windows.</li>
  <li><a href="https://docs.microsoft.com/en-us/windows/wsl/install-win10">Windows subsystem for Linux</a>(WSL): a 
full Linux emulator, which is bundled with all new Windows 10 installations. WSL is more powerful 
and fully-featured than Cygwin or Git for Windows and even lets you run programs compiled for Linux
from the Windows command-line, but it’s a bit trickier to install than the other two tools.</li>
</ul>

<p>You’ll also need to use SSH to connect and login to the cluster. Fortunately, Windows 10 includes its
own SSH program by default. It can be accessed by running <code class="language-plaintext highlighter-rouge">ssh.exe</code> in any of the programs listed
above, or in the Windows command line. More detailed instructions for using SSH can be found in the
<em>Logging in</em> section of this guide.</p>

<h2 id="where-to-get-help">Where to get help</h2>
<p>If you get stuck, there are several places you can check for help. Unfortunately there is not much
standardisation of documentation between programs, but there are a few “safe bets” to check first.</p>

<p>The first port of call should always
be the manuals, referred to as <em>man pages</em>, which come bundled with Linux. These are accessed by the
terminal command <code class="language-plaintext highlighter-rouge">man</code>, followed by the name of the program you want to read about. For example, you can
access the manual page for the <code class="language-plaintext highlighter-rouge">less</code> command by typing <code class="language-plaintext highlighter-rouge">man less</code> at the command prompt. If you don’t
remember the specific name of the command, you can search the man pages with <code class="language-plaintext highlighter-rouge">apropos</code>. For example,
running <code class="language-plaintext highlighter-rouge">apropos editor</code> will search for any man pages which include the word <code class="language-plaintext highlighter-rouge">editor</code> in their name or
description (in this case, it returns the names of lots of different text editor programs). Bash also 
has a command called <code class="language-plaintext highlighter-rouge">info</code> which will read “information documents” about a given file. It is
similar to <code class="language-plaintext highlighter-rouge">man</code>, but some programs may have an <code class="language-plaintext highlighter-rouge">info</code> page but not a <code class="language-plaintext highlighter-rouge">man</code> page.</p>

<p>Sometimes a program won’t come with a man page, but the developers might still provide documentation.
Almost all programs follow a similar convention here: adding <code class="language-plaintext highlighter-rouge">--help</code> or <code class="language-plaintext highlighter-rouge">-h</code> after the program’s 
command will almost always make it print a help message (usually including a short description and a
list of arguments/parameters it accepts). For example, running the command <code class="language-plaintext highlighter-rouge">less --help</code> will show a
summary of commands that the program <code class="language-plaintext highlighter-rouge">less</code> accepts, as well as general advice on how to use it. 
Unfortunately, different programs may use either <code class="language-plaintext highlighter-rouge">--help</code> or <code class="language-plaintext highlighter-rouge">-h</code> or both, so you’ll have to try them to
find out. These optional parameters which modify commands’ behaviour are referred to as <em>flags</em>.</p>

<p>Finally, managed HPC clusters usually have very good online documentation. The big three you’re likely
to use at UQ are <a href="http://www2.rcc.uq.edu.au/hpc/guides/index.html?secure/Reading_Guide.html">UQ’s Research Computing
Centre</a> (for Tinaroo and 
Awoonga), <a href="https://opus.nci.org.au/display/Help/Gadi+User+Guide">NCI</a> (for Gadi), and 
<a href="https://support.pawsey.org.au/documentation/display/US/User+Support+Documentation">the Pawsey Centre</a> 
(for Magnus). These online resource contain both general information (e.g. compiling and using 
software), and information specific to using those clusters (e.g. running and checking the status of
computational jobs).</p>

<h2 id="logging-in">Logging in</h2>
<p>Before you can use the clusters, you’ll need to apply for an account with the organisation that manages
them - your supervisor will be able to tell you which ones you’ll be using and will need to approve your
application. The relevant signup forms are:</p>
<ul>
  <li>RCC (Tinaroo, Awoonga and Wiener): <a href="https://rcc.uq.edu.au/high-performance-computing">https://rcc.uq.edu.au/high-performance-computing</a></li>
  <li>NCI (Gadi): <a href="https://my.nci.org.au/mancini/signup/0">https://my.nci.org.au/mancini/signup/0</a></li>
  <li>Pawsey (Magnus): <a href="https://pawsey.org.au/support/">https://pawsey.org.au/support/</a></li>
</ul>

<p>Once your account is established, the next step is to log on to the cluster over the internet via a
program called <em>SSH</em>. This will establish a connection between your computer’s terminal and the
cluster’s login node, so that any commands you type into SSH will be set across the network and executed
on the cluster, with the results sent back across the network to be displayed on your computer. Take
note that the SSH connection is bound to the terminal window in which you ran the SSH command (either
<code class="language-plaintext highlighter-rouge">ssh</code> on Mac or Linux, or <code class="language-plaintext highlighter-rouge">ssh.exe</code> on Windows), so any commands you type in other terminal windows 
(including ones you start after you launch SSH) will be executed on you computer and not on the cluster.</p>

<p>If you’re using Mac or Linux, open a terminal window and run the command <code class="language-plaintext highlighter-rouge">ssh
&lt;username@cluster.address&gt;</code> where you replace <code class="language-plaintext highlighter-rouge">username</code> with your username on the cluster (which would 
have been sent in an email when you signed up) and <code class="language-plaintext highlighter-rouge">cluster.address</code> is the network address of the 
cluster - this can be found in the online documentation of the cluster you’re logging in to. The SSH 
commands for the big-three clusters you’re likely to use are:</p>

<table>
  <tbody>
    <tr>
      <td>Tinaroo(RCC)</td>
      <td><code class="language-plaintext highlighter-rouge">ssh username@tinaroo.rcc.uq.edu.au</code></td>
    </tr>
    <tr>
      <td>Awoonga(RCC)</td>
      <td><code class="language-plaintext highlighter-rouge">ssh username@awoonga.rcc.uq.edu.au</code></td>
    </tr>
    <tr>
      <td>Wiener(RCC)</td>
      <td><code class="language-plaintext highlighter-rouge">ssh username@wiener.hpc.dc.uq.edu.au</code></td>
    </tr>
    <tr>
      <td>Gadi (NCI)</td>
      <td><code class="language-plaintext highlighter-rouge">ssh username@gadi.nci.org.au</code></td>
    </tr>
    <tr>
      <td>Magnus (Pawsey)</td>
      <td><code class="language-plaintext highlighter-rouge">ssh username@magnus.pawsey.org.au</code></td>
    </tr>
  </tbody>
</table>

<p>Your terminal may print a warning about “unknown server”, type “yes” to continue. The process is almost
the same on Windows, except you need to open a command line window (either <code class="language-plaintext highlighter-rouge">cmd.exe</code> or Powershell) and
run <code class="language-plaintext highlighter-rouge">ssh.exe &lt;username@cluster.address&gt;</code>.</p>

<p>If there are no errors, you should now see a new <em>prompt</em> (the words and characters just to the left of
where commands appear when you type) that looks something like <code class="language-plaintext highlighter-rouge">username@magnus-1:~&gt;</code> (it will be
different for different clusters), which means that any commands you type in this window will be
executed on the cluster. Congrats! You’re now using a supercomputer.</p>

<p>Many clusters (including Magnus, Gadi and Tinaroo) will print a welcome notice when you first SSH in. 
This notice usually includes information on upcoming maintenance, information about recent changes to 
the system and a reminder of where to get help. These are usually worth paying attention to, as it’s one
of the main way that the cluster’s maintainers get information to you.</p>

<p>Finally, when you’re finished with the remote session, type <code class="language-plaintext highlighter-rouge">exit</code> to close the SSH connection and
logout. Most of the time, the SSH connection will automatically close if you leave it unattended for too
long (where “too long” could be anywhere from an hour to a day), but that can be messy so it’s always
best to explicitly log out when you’re finished.</p>

<h2 id="getting-around---navigating-the-file-system">Getting around - navigating the file system</h2>
<p>It’s important to understand how to navigate and use the <em>file system</em> on the cluster. Broadly speaking,
data on the computer is stored in files, which are grouped together into a hierarchy of <em>directories</em>
(also called <em>folders</em>). This holds true on Windows, Mac and Linux. You may be used to navigating the
file system and manipulating files (e.g. copying, renaming or deleting) through a graphical program
called a <em>file manager</em> such as <em>Finder</em> on Mac or <em>File Explorer</em> on Windows. Since the clusters you’ll
be using do not have a graphical interface, you’ll need to use the command line to manipulate files on
the cluster.</p>

<p>There is an extra degree of complexity on HPC clusters, compared to a personal workstation, as files 
need to be accessible to all
nodes on the cluster (not just the one physically attached to the disk). The exact details will vary
from machine to machine, but you can usually count on there being two main “locations” to store files:</p>

<ul>
  <li>Your home directory: this directory is usually <em>persistent</em> storage, so files stored in the home
directory (or its sub-folders) are backed up and last until you delete them or your account no 
longer exists. It usually has small storage capacity, so only essential files that you don’t want to
lose should be stored here. Equivalent to “My Documents, My Pictures, etc” on Windows or “Home” on
Mac, it is labeled with your username on the cluster.</li>
  <li>Scratch space: this directory usually has a lot of storage capacity, but is usually not backed up,
so it’s a good idea to transfer files to home (or off the cluster entirely) if you’ll need them
later. What’s more, some systems (including RCC and Pawsey) regularly purge unused files, which is
even more reason to transfer them off when you’re done.</li>
</ul>

<p>All directories have certain <em>permissions</em>, which determine who can access files stored in them. You
will always have permission to read from and write to files in your home directory and in your folder
in scratch space (which is labeled with your username on the cluster), while you may have read-only
permission for files in directories belonging to other members of your group. You will not be permitted
to access files belonging to other users not in your group.</p>

<p>On Linux, all directories and files are identified, or “located”, with a <em>file path</em>, in which
directories and sub-directories are separated by <code class="language-plaintext highlighter-rouge">/</code> characters (this is different to Windows which uses
the <code class="language-plaintext highlighter-rouge">\</code> character). For example, your home directory might have the path <code class="language-plaintext highlighter-rouge">/home/username/</code>, which
indicates that the <code class="language-plaintext highlighter-rouge">username</code> folder is a sub-folder of the <code class="language-plaintext highlighter-rouge">/home</code> folder (which holds the home
directories of every user on the system). The paths to home and scratch space on clusters could be
quite long, so you’ll need to look it up in the cluster’s online documentation. Since the exact location
will differ between systems, Linux provides the shortcut <code class="language-plaintext highlighter-rouge">~/</code> which will always refer to your home
directory, whatever its actual path.</p>

<p>Directories are like “places”, analogous to drawers in a filing cabinet, and you will be “in” exactly
one “place” whenever you’re logged in with the shell. This is called the “working directory”
Commands you type will execute “in” this place,
for example by reading and writing files, so it’s important to make sure you’re in the right directory
before you do anything. Linux provides the shortcut <code class="language-plaintext highlighter-rouge">./</code> which refers to the current directory, as well
as the shortcut <code class="language-plaintext highlighter-rouge">../</code> which refers to the current <em>parent</em> directory (i.e. the directory “above” the
current working directory, so if you’re in <code class="language-plaintext highlighter-rouge">/home/username/data/run</code> then <code class="language-plaintext highlighter-rouge">../</code> will refer to
<code class="language-plaintext highlighter-rouge">/home/username/data</code>). Any other filenames which start with a ‘.’ character are “hidden files”, which
are not included in file listings unless requested with specific flags (more on that in a moment).</p>

<p>There are a couple of bash commands which are important to know when navigating
the file system:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">pwd</code> (stands for “print working directory”): prints the path of the current working directory.</li>
  <li><code class="language-plaintext highlighter-rouge">cd *dir*</code> (stands for “change directory”): moves you to the specified directory. For example <code class="language-plaintext highlighter-rouge">cd ~/</code> 
will change the working directory (or “move” you) to your home directory.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">ls</code> (short for “list”): prints a list of files in the current directory. You can also type a
directory path after <code class="language-plaintext highlighter-rouge">ls</code> and it will print the names of files in the target directory (instead of the
current one). For example, <code class="language-plaintext highlighter-rouge">ls ~/data</code> will print all files in the <code class="language-plaintext highlighter-rouge">data</code> directory, a sub-directory
of your home directory (assuming it exists).</p>

    <p>Three import flags to remember are <code class="language-plaintext highlighter-rouge">-l</code> (“long output”), <code class="language-plaintext highlighter-rouge">-h</code> (“human-friendly”) and <code class="language-plaintext highlighter-rouge">-a</code> (“all”).</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">cp &lt;src&gt; &lt;dest&gt;</code> (short for “copy”): copies a file from one location (the source, abbreviated to 
<code class="language-plaintext highlighter-rouge">src</code>) to another (the destination, <code class="language-plaintext highlighter-rouge">dest</code>). For example, to transfer the file <code class="language-plaintext highlighter-rouge">output.txt</code> from the
current directory to the home directory, you would run <code class="language-plaintext highlighter-rouge">cp output.txt ~/output.txt</code>. If you do
not provide a filename in the destination then the new file will have the same name as the old one, so
the previous command could be shortened to <code class="language-plaintext highlighter-rouge">cp output.txt ~/</code>. Be careful when copying files: if you
give a destination filename which already exists, then <code class="language-plaintext highlighter-rouge">cp</code> will overwrite it <strong>without warning you</strong>.
You can give the <code class="language-plaintext highlighter-rouge">-i</code> flag to <code class="language-plaintext highlighter-rouge">cp</code> to tell it to ask for confirmation before overwriting any files
(e.g. <code class="language-plaintext highlighter-rouge">cp -i &lt;src&gt; &lt;dest&gt;</code>). This command is conceptually equivalent to copying and pasting with 
<em>File Explorer</em> (Windows) or <em>Finder</em> (Mac).</li>
  <li><code class="language-plaintext highlighter-rouge">mv &lt;src&gt; &lt;dest&gt;</code> (short for “move”): similar to <code class="language-plaintext highlighter-rouge">cp</code> except it moves the source file, rather than 
copying it. This means that after <code class="language-plaintext highlighter-rouge">mv</code> has completed, the original file will no longer be present -
it will have moved completely to the new destination. Like with <code class="language-plaintext highlighter-rouge">cp</code>, <code class="language-plaintext highlighter-rouge">mv</code> will not warn you if you’re
about to overwrite a file, unless you pass it the <code class="language-plaintext highlighter-rouge">-i</code> flag`. This command is conceptually equivalent 
to cutting and pasting with <em>File Explorer</em> (Windows) or <em>Finder</em> (Mac).</li>
  <li><code class="language-plaintext highlighter-rouge">rm &lt;file1&gt; &lt;file2&gt; ...</code> (short for “remove”): delete the specified file(s) from the system. Be aware
that there is no equivalent to the “Recycle Bin” on HPC clusters, so make doubly sure you want a file
gone before you delete anything with <code class="language-plaintext highlighter-rouge">rm</code>. <code class="language-plaintext highlighter-rouge">rm</code> will also not remove directories without the <code class="language-plaintext highlighter-rouge">-r</code>
flag, so you must do <code class="language-plaintext highlighter-rouge">rm -r &lt;dir&gt;</code> to delete a directory.</li>
  <li><code class="language-plaintext highlighter-rouge">mkdir &lt;dir&gt;</code> (stands for “make directory”): create the specified directory, which can be either a
relative or absolute path. <code class="language-plaintext highlighter-rouge">mkdir</code> will fail and print an error if the specified directory already
exists.</li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">tree</code>: similar in concept to <code class="language-plaintext highlighter-rouge">ls</code>, but used for visualising the entire directory structure in a 
convenient “tree”-like representation. Unlike <code class="language-plaintext highlighter-rouge">ls</code>, <code class="language-plaintext highlighter-rouge">tree</code> is *recursive, which means it will not only
display the contents of the target directory (or current directory if not given any arguments), but
also the contents of each sub-directory, and so on until there are no more files to display. The
output is formatted like a tree (the abstract structure from graph-theory, not a biological tree),
with the current directory at the root node and with each node’s children representing the files and
folders it contains.</p>

    <p>For example, say we have a directory called data, which contains some files and two sub-folders
<code class="language-plaintext highlighter-rouge">Aggregator</code> and <code class="language-plaintext highlighter-rouge">Interface</code>. Running <code class="language-plaintext highlighter-rouge">ls</code> while in <code class="language-plaintext highlighter-rouge">data</code> would show:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Aggregator  Interface  timing.dat  SSGK.in template_SSGK.in
</code></pre></div>    </div>
    <p>Which tells us what’s in the current directory, but we’d need to run <code class="language-plaintext highlighter-rouge">ls</code> on all of the sub-folders
(<code class="language-plaintext highlighter-rouge">Aggregator</code> and <code class="language-plaintext highlighter-rouge">Interface</code>) to find out what’s in <em>them</em>.</p>

    <p>On the other hand, running <code class="language-plaintext highlighter-rouge">tree</code> in the same directory would show us:</p>
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tree
.
├── Aggregator
│   ├── aggregate.awk
│   ├── Parallel
│   │   ├── INTCF1_3
│   │   ├── PROPS
│   │   ├── PROPS_2
│   │   ├── TCF1_2
│   │   └── TCF_3
│   └── Serial
│       ├── INTCF1_3
│       ├── PROPS
│       ├── PROPS_2
│       ├── TCF1_2
│       └── TCF_3
├── Interface
│   └── F77
│       ├── base.in
│       └── VELOCITY_TEMP
├── timing.dat
├── SSGK.in
└── template_SSGK.in
</code></pre></div>    </div>
    <p>This view provides much more information: we can see that <code class="language-plaintext highlighter-rouge">Aggregator</code> has two-subdirectories, while
<code class="language-plaintext highlighter-rouge">Interface</code> has one, as well as what files are in those sub-directories. While this is a somewhat
simplified example, <code class="language-plaintext highlighter-rouge">tree</code> can be very useful when navigating an unfamiliar directory structure, such
as a large, unfamiliar codebase (maybe you need to learn how to use some open-source simulation
software) or a complex data-set.</p>
  </li>
</ul>

<p>Typing out a long filename and path can be tedious and error-prone, so bash provides a shortcut called
<em>tab-completion</em>. Pressing tab while part-way through typing a command will automatically fill-in the
rest of the command: if you type <code class="language-plaintext highlighter-rouge">cd /home/username/da</code> and hit the “tab” key, the shell will complete
the rest of the command to <code class="language-plaintext highlighter-rouge">cd /home/username/data</code> (it will only fill in the command, but not execute
it. You still need to hit “enter” to execute the complete command). If there are multiple possible
results which a partial command could complete to, then the shell will only fill in part they have in
common. As an example, there are multiple command line programs which start with the letters “tr”, so if
you type <code class="language-plaintext highlighter-rouge">tr</code> and hit “tab” then bash will not be able to decide which one to complete to so it will do
nothing. Pressing “tab” a second time will print a list of all the possible matches, which might look
like:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ tr
tr           traceroute   trap         troff        trust        
tracepath    traceroute6  tred         true         
tracepath6   tracker      tree         truncate
</code></pre></div></div>
<p>You can then continue typing the command you want, and if you press “tab” again after typing a few more
letters then bash will fill in as much as it can again. You can do this as many times as you like when
typing out a command, which has the dual benefit of cutting down on the amount of typing you need to do,
while also providing reminders of the available directories or commands.</p>

<p>Sidebar for Mac users: tab-completion <em>does</em> work natively on the macOS terminal, but may require some
extra configuration to achieve the above behaviour. By default, tab-completion will not list possible
matches for an ambiguous completion; it will make an alert sound instead (unless you have disabled
system sounds). In order
to change this, you will need to edit the file <code class="language-plaintext highlighter-rouge">~/.inputrc</code> (the easiest way to do this is via the
<code class="language-plaintext highlighter-rouge">TextEdit</code> program), and add the following two lines:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>set show-all-if-ambiguous on
TAB: menu-complete
</code></pre></div></div>

<p>Finally, even though Linux imposes very few technical restrictions on what name a file or directory can
have, there are still some “best practices” which will make your life much easier. First, spaces in
filenames can be extremely annoying to deal with on the command line: since bash uses spaces to
determine when a new command or flag has started, spaces in filenames need special treatment to work
properly. Let’s say you have a file called <code class="language-plaintext highlighter-rouge">calculation results.txt</code>. If you were to type <code class="language-plaintext highlighter-rouge">rm
calculation results.txt</code>, bash would interpret the space to mean that you’re actually referring to <em>two</em>
filess called <code class="language-plaintext highlighter-rouge">calculation</code> and <code class="language-plaintext highlighter-rouge">results.txt</code>, neither of which are the original file. Instead, you need
to <em>escape</em> the “space” in the name by prefixing it with a backslash (“"): <code class="language-plaintext highlighter-rouge">rm calculation\
results.txt</code>. You’ll need to do this for every space in a filename, as well as other <em>special
characters</em>, like asterisks (“*”), brackets (“(“ and “)”) and ampersands (“&amp;”) (a complete list of all
special characters in bash can be found here: <a href="http://mywiki.wooledge.org/BashGuide/SpecialCharacters">http://mywiki.wooledge.org/BashGuide/SpecialCharacters</a>).</p>

<p>It’s best to avoid using spaces and other special characters entirely, since constantly escaping
characters in a filename is tedious and error-prone. So what should you do if you want to make a
filename that contains multiple words? The best option is to use either a hyphen (“-“) or underscore
(“_”) where you would usually use a space to separate words, so our example file would become
either <code class="language-plaintext highlighter-rouge">calculation-results.txt</code> or <code class="language-plaintext highlighter-rouge">calculation_results.txt</code>. Either option is fine, but it’s best to
pick one and stick with it, since using a consistent naming scheme makes it easier to remember and
search through files.</p>

<h3 id="where-to-store-your-files-on-the-cluster">Where to store your files on the cluster</h3>
<p>So now that you know how to navigate the file-system, you may be wondering “where and how should I store
all my files?”. Like we saw before, HPC clusters tend to have very specifically structured file-systems,
so it’s important to make sure that you’re using them as intended to get the most out of the system.</p>

<p>As with everything in this guide, different clusters will have different guidelines for file-system
access, so it’s a good idea to at least skim the manual pages. For RCC, the relevant page is
<a href="http://www2.rcc.uq.edu.au/hpc/guides/index.html?secure/Storage_userguide.html"></a> (must log in with your
UQ credentials to access it), for NCI it is
<a href="https://opus.nci.org.au/display/Help/3.+Storage+and+Data+Management"></a>, while for Pawsey it is
<a href="https://support.pawsey.org.au/documentation/display/US/File+Systems%2C+File+Transfers+and+File+Management"></a>
(which even comes with a nice video tutorial!). All systems use the same general principles, however.</p>

<p>Generally speaking, it’s best not to run calculations inside your home directory: if your calculation
generates lots of temporary files then it could overwhelm the filesystem and make it unresponsive for
all users. Not only is this bad for your code’s performance, you’ll probably get a cranky email from the
system administrator telling you to knock it off (which is never fun). Instead, you should run jobs in a
temporary directory on the scratch space. Scratch filesystems are usually designed to handle lots of
activity without slowing under the load, while also having much more storage available for use than your
home directory will. On <em>Gadi</em> and <em>Magnus</em>, the scratch directory has the path
<code class="language-plaintext highlighter-rouge">/scratch/&lt;PROJECT&gt;/username</code> (where you replace <code class="language-plaintext highlighter-rouge">PROJECT</code> with the project code your research group is
using. Ask your supervisor for this if you’re unsure. Replace <code class="language-plaintext highlighter-rouge">username</code> with the username you use to
login to Magnus or Gadi), while the RCC systems have <code class="language-plaintext highlighter-rouge">/30days/&lt;username&gt;</code>
and <code class="language-plaintext highlighter-rouge">/90days/&lt;username&gt;</code> (where <code class="language-plaintext highlighter-rouge">username</code> is your UQ username). As the name might suggest, <code class="language-plaintext highlighter-rouge">/30days</code> is
cleared out every 30 days, while <code class="language-plaintext highlighter-rouge">/90days</code> is cleared out every 90 days.</p>

<p>Once you’ve generated your data, you should move the important files to your home directory in one go. 
Remember that scratch space is usually not backed-up and is regularly cleared out on Pawsey and RCC 
systems, so it’s crucial that you move any important results or data to your home directory for safe 
keeping.</p>

<h2 id="reading-and-editing-text">Reading and editing text</h2>
<p>Reading and editing documents via the Linux command line is not too dissimilar to doing so via a
graphical interface. The biggest difference is that almost everything you’ll use to run calculations and
analyse the output will be plain text documents (which universally have the <code class="language-plaintext highlighter-rouge">.txt</code> filename suffix), so
you won’t be able to use a word processor like MS Word or Mac Pages to edit them (they do too
much automatic formatting, spell-checking, save in the wrong file format, etc). But even on the command
line, there are a range of powerful, easy-to-use programs for editing text available on almost clusters.</p>

<p>First, let’s talk about viewing the contents of text files. Sometimes you don’t necessarily want to edit
a file, but need to know what’s in it, and often you’ll need to see the contents at a specific line or
lines. There are four main command line tools to do this:</p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">less</code>: a type of program known as a <em>pager</em>, which allows you to display and scroll back and forth
through the contents of a file. <code class="language-plaintext highlighter-rouge">less</code> only reads the parts of the file that it currently needs, so it
can be much faster than a text editor when you need to view the contents of extremely large text files
(i.e. &gt; 100,000 lines, not unusual for simulation output).</li>
  <li><code class="language-plaintext highlighter-rouge">cat</code> (short for “concatenate”): prints the entire contents of a file or files to the terminal window,
without the ability to scroll back and forth. If multiple file names are passed to <code class="language-plaintext highlighter-rouge">cat</code>, then it will
print their contents one after the other, essentially joining, or concatenating, the output (note that
this does not change the contents of any of the input files). For example, if the file <code class="language-plaintext highlighter-rouge">file1.txt</code>
contains the line <code class="language-plaintext highlighter-rouge">foo</code> and <code class="language-plaintext highlighter-rouge">file2.txt</code> contains the line <code class="language-plaintext highlighter-rouge">bar</code>, then running <code class="language-plaintext highlighter-rouge">cat</code> would give:
    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat file1.txt file2.txt
foo
bar
</code></pre></div>    </div>
    <p>which is useful for tasks like combining multiple data files into a single text file.</p>
  </li>
  <li><code class="language-plaintext highlighter-rouge">head</code> and <code class="language-plaintext highlighter-rouge">tail</code>: these are mentioned together, as they perform very similar roles. <code class="language-plaintext highlighter-rouge">head</code> prints the
first 10 lines of a file to the terminal, while <code class="language-plaintext highlighter-rouge">tail</code> prints the last 10 lines. These default values
can be overridden via the <code class="language-plaintext highlighter-rouge">-n &lt;num&gt;</code> command-line flag, so to print the first 20 lines of <code class="language-plaintext highlighter-rouge">data.txt</code>
you would run <code class="language-plaintext highlighter-rouge">head -n 20 data.txt</code>.</li>
</ul>

<p>Now, for actually editing text files, there are three major text editors available on almost every Linux
system:</p>

<ul>
  <li><a href="https://www.nano-editor.org/docs.php">nano</a>: a simple, no-frills text editor. It has no special
features - it just opens, writes and saves text files. Nano is very easy to use, and is the closest
equivalent to a “notepad” type application on the Linux command-line. Magnus requires you to load the
<code class="language-plaintext highlighter-rouge">nano</code> module before you can use it (via <code class="language-plaintext highlighter-rouge">module load nano</code>).</li>
  <li><a href="https://www.linux.com/training-tutorials/vim-101-beginners-guide-vim/">vim</a>: a more
fully-featured and customisable text editor with loads of special features like syntax-highlighting
and the ability to define custom macros. The flip-side of this
extra flexibility is that it has a somewhat steep learning curve. Vim is available on every Linux
system you are likely to encounter, with no special effort required (just run <code class="language-plaintext highlighter-rouge">vim</code> in the
command-line).</li>
  <li><a href="https://www.gnu.org/software/emacs/tour/">emacs</a>: a text editor with is similarly full-featured and
customisable as vim, albeit with a completely different user-interface. Emacs also has a steep
learning curve, but can be very powerful once you learn it. Again, emacs will be available on every
Linux system you are likely to encounter.</li>
</ul>

<p>If you want to edit text files on your personal computer before transferring them to the cluster, some
useful open-source graphical applications are:</p>

<ul>
  <li><a href="https://atom.io/">Atom</a> (Windows, Mac, Linux)</li>
  <li><a href="https://geany.org/">Geany</a> (Windows, Mac, Linux)</li>
  <li><a href="https://notepad-plus-plus.org/">notepad++</a> (Windows only)</li>
  <li><a href="https://kate-editor.org/">Kate</a> (Windows, Mac, Linux)</li>
</ul>

<p>All of the above applications are free and open-source and support “advanced” features like 
syntax-highlighting for programming languages, autosaving and tabbed editing. The default text editors
on Windows and Mac (notepad and TextEdit, respectively) can also be used, but are extremely barebones
and lack nice usability features. If you’re going to be writing code, then it may be worthwhile using a
full integrated development environment (IDE) as well. An IDE will do syntax highlighting, automatic
code correctness checks and most have integrated debugging and source code management tools which makes
the development process much easier. Microsoft <a href="https://code.visualstudio.com/">Visual Studio Code</a> (or
the full <a href="https://visualstudio.microsoft.com/">Visual Studio</a> on Windows) is a free IDE for Windows, Mac
and Linux which will be sufficient for most code development you’re likely to do.</p>

<h2 id="output-redirection-and-pipes">Output redirection and pipes</h2>
<p>There are two very important, Unix-specific ways of manipulating text that has no clear analogue in
graphical applications: <em>output rediction</em> and <em>pipes</em>. These concepts are key to using the command line
effectively, and are best explained with specific examples.</p>

<p>When you run a command in the shell, it will usually print its output to the active terminal window;
referred to as printing to <em>standard output</em>, or <code class="language-plaintext highlighter-rouge">stdout</code> for short. Sometimes a program will
need to print error messages, which is referred to as printing to <em>standard error</em>, or <code class="language-plaintext highlighter-rouge">stderr</code>.
Although both <code class="language-plaintext highlighter-rouge">stdout</code> and <code class="language-plaintext highlighter-rouge">stderr</code> both print to the terminal window by default, it is possible to
save one or both to a file or use the output of one program as the input for another program - referred
to as <em>output redirection</em>. In bash, output redirection is represented by the syntax <code class="language-plaintext highlighter-rouge">prog &gt; file</code>,
which says that the standard output from <code class="language-plaintext highlighter-rouge">prog</code> will be saved to <code class="language-plaintext highlighter-rouge">file</code> instead of printed to the
terminal. A command’s standard error can be redirected with a similar syntax: <code class="language-plaintext highlighter-rouge">prog 2&gt; file</code>. Finally,
an important warning: redirecting output to an existing file with <code class="language-plaintext highlighter-rouge">&gt;</code> will completely overwrite its
contents, which may not be what you intended to do. If you want to <em>append</em> the output of a command to
a file (i.e. preserving the original contents) such as when keeping a log of some simulation run, you
must instead use <code class="language-plaintext highlighter-rouge">&gt;&gt;</code> (e.g. <code class="language-plaintext highlighter-rouge">prog &gt;&gt; file</code>).</p>

<p>Output redirection is wonderful for saving the results of programs for later use (it saves you manually
copy-pasting the output of a simulation once it’s done), but is limited to saving output to a file. If
we want to do something fancier, we can use a related concept called <em>pipelines</em>. Bash (and other
shells) use the <code class="language-plaintext highlighter-rouge">|</code> character to indicate that the output of the preceding program should be redirected,
or <em>piped</em>, into the input of the next. For example, if we want to pipe the output of <code class="language-plaintext highlighter-rouge">prog1</code> into
<code class="language-plaintext highlighter-rouge">prog2</code> we would type <code class="language-plaintext highlighter-rouge">prog1 | prog2</code>. Multiple pipes can be used in a single command, and programs in a
pipeline are run <em>concurrently</em> - <code class="language-plaintext highlighter-rouge">prog1</code> and <code class="language-plaintext highlighter-rouge">prog2</code> are started at the same time, and <code class="language-plaintext highlighter-rouge">prog2</code>
processes data from <code class="language-plaintext highlighter-rouge">prog1</code> as soon as it becomes available. This means that combining programs in a 
pipeline is both more flexible than writing a single large program to do everything, and also faster, 
since it automatically exploits some of the available parallelism in the overall task.</p>

<p>This has all been very abstract, so let’s look at some concrete examples. A very common use for pipes 
(probably the one that I use most in terms of sheer frequency) is piping very large output streams to 
<code class="language-plaintext highlighter-rouge">less</code>, to make it easier to read and scroll through. As we saw in <em>Getting around - navigating the file
system</em>, the command <code class="language-plaintext highlighter-rouge">tree</code> can produce a <em>lot</em> of output if run in a deeply nested directory. It’s much
easier to read the output if we pipe it through <code class="language-plaintext highlighter-rouge">less</code> by doing <code class="language-plaintext highlighter-rouge">tree | less</code>. Similarly, if we only
wanted to see the first few lines of output, we could do <code class="language-plaintext highlighter-rouge">tree | head</code>.</p>

<p>There’s more to pipes than just making output easier to read, though. Linux has a wide range of little
utilities which do one task, and are designed to be slotted into pipelines. To borrow a metaphor from
the early days of Unix <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote">1</a></sup>, pipelines are a way “of coupling programs like garden hose - screw in 
another segment when it becomes when it becomes necessary to massage data in another way”. Essentially,
pipelines allow us to do ad-hoc data analysis in the shell, without having to write our own tools from
scratch in Python Fortran.</p>

<p>For example,
the <code class="language-plaintext highlighter-rouge">grep</code> command searches through a stream of text (either the contents of a file or the output of a
command) and prints all lines containing a specific pattern (e.g. a string). Let’s say we want to search
through the output of some program for the string “CH4” - we can either save the output to a file and
search that file:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./prog &gt; output.txt
$ grep "CH4" output.txt
</code></pre></div></div>

<p>or we can compress these two steps into one command by piping the output into <code class="language-plaintext highlighter-rouge">grep</code>:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./prog | grep "CH4" 
</code></pre></div></div>
<p>which is easier to read, and will be much faster since <code class="language-plaintext highlighter-rouge">grep</code> will print the lines as the are produced,
rather than having to wait for the program to finish. Furthermore, if we wanted to then save the first
15 matching lines to a file, we could extend our pipeline with <code class="language-plaintext highlighter-rouge">head</code> and output redirection into:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ ./prog | grep "CH4" | head -n 15 &gt; output.txt
</code></pre></div></div>

<p>http://doc.cat-v.org/unix/pipes/.</p>

<p>Pipes are one of the most important concepts covered in this document, and using them effectively is
key to getting the most out of the Linux command-line.</p>

<h2 id="automate-common-tasks---command-line-scripting">Automate common tasks - command-line scripting</h2>
<p>In addition to typing in commands and receiving the responses one at a time (so-called <em>interactive
use</em>), bash supports the ability to write short programs called <em>shell scripts</em> which contain a sequence
of commands to be executed automatically. Since this provides the ability to group a number of commands
together and execute in a “batch”, they are also often called <em>batch scripts</em> (which is the most common
terminology in Windows).</p>

<p>A shell script is just a plain text file which contains some commands for bash to execute, and has
functionally the same syntax as typing directly into the command line. Before it can be executed,
though, the operating system (Linux) needs to know what type of script is contained in a text file. This
is achieved with a construct known as a “shebang”: the characters <code class="language-plaintext highlighter-rouge">#!</code> followed immediately by the path
to the shell program. On most systems, this will be <code class="language-plaintext highlighter-rouge">/bin/bash</code>, so your shell-scripts must start with
the line: <code class="language-plaintext highlighter-rouge">#!/bin/bash</code>. The shebang must be the first line in the script, otherwise it will not work.
Additionally, the convention is to use the <code class="language-plaintext highlighter-rouge">.sh</code> suffix for shell script files (e.g. <code class="language-plaintext highlighter-rouge">script.sh</code>), but
this is only to make it easier to remember what different files do - the Linux operating system does not
care what you call the file as long as it has the shebang in the right place.</p>

<p>Any other lines starting 
with a “#” are ignored by the shell and do not affect execution of the script; they are <em>comments</em> which
serve to document and explain what the script is doing. As with all programming, it is a good idea to
write a comment whenever you’re doing something which may not be immediately obvious to somebody
unfamiliar with the script (this could be one of your co-workers, or it could be you in six months
time).</p>

<p>The rest of the script can contain any number of commands, which will be executed in sequence (i.e. in
the same order as they appear in the file) and will have the same results as if you had entered the
commands yourself: they will print output, modify files and, for certain commands, ask for confirmation
before proceeding.</p>

<p>Once you’ve written your script, you need to tell the operating system that it’s a program to be run,
rather than just a static text file. This is referred to as “marking it as executable” or “giving it
executable permissions”, and is achieved by the command <code class="language-plaintext highlighter-rouge">chmod +x &lt;script&gt;</code> (<code class="language-plaintext highlighter-rouge">chmod</code> stands for “change
mode” and the <code class="language-plaintext highlighter-rouge">+x</code> stands for “e<strong>x</strong>ecute”). Once the script is executable, you can run it by typing out
the name and path of the script. If you’re in the same directory as the script (the most common case),
this can be shortened by using the “./” shortcut, so if we have a script called <code class="language-plaintext highlighter-rouge">script.sh</code> then we can
execute it by typing <code class="language-plaintext highlighter-rouge">./script.sh</code>.</p>

<p>Shell-scripting has some very advanced features on top of just running commands (far too many
to fit in this introduction), but the most important use-case for scripts when you’re starting out is to
automate common work-flows and pipelines. Typing the same command (or set of commands) out multiple
times in a row is tedious and error-prone (typos, accidentally using the wrong flag, etc), so if you
find you find yourself using the same commands or pipelines more than three times then it’s a good idea
to transform it into a script. Saving complicated pipelines or sequences of commands in a script also
makes it easier to remember them later on - rather than needing to memorise the exact sequence of
commands used to generate a file you just need to look at the contents of the script.</p>

<p>Shell scripting is also important because it is the way we submit and run computational jobs on HPC
clusters.</p>

<h2 id="hpc-clusters---the-basics-of-submitting-jobs">HPC clusters - the basics of submitting jobs</h2>
<p>HPC clusters can have hundreds or thousands of users sharing the same set of resources, so they use
software called a <em>job scheduler</em> to ensure everyone gets has fair access to the cluster. In order to
run simulations on the cluster, you need to create a <em>job script</em>, which is a program (written in the
<em>bash scripting language</em>) that tells the
scheduler what sort of job you’d like to run: how many CPUs you need, how much memory you think you’ll
need, how long you think it’ll take, and what programs to run. The job scheduler then uses all of your
requests to calculate a <em>priority</em> and places your job in a queue (which could contain dozens or
hundreds of jobs from other users). When it’s your job’s turn, and there are enough free resources, then
the job scheduler will run your script. You can submit multiple jobs to the queue at the same time,
potentially requiring different sets of resources for each job, and the scheduler will handle the
queueing and running automatically.</p>

<p>Making a job script from scratch can be a little bit fiddly, and each cluster has its own way of
handling jobs, with RCC and NCI using software called <em>PBS Pro</em>, while Pawsey uses <em>SLURM</em> as its job
scheduler.
Fortunately the major clusters have online documentation with example job scripts you
can modify to suit your needs:</p>

<ul>
  <li>RCC: <a href="http://www2.rcc.uq.edu.au/hpc/guides/index.html?secure/Batch_PBSPro.html">Documentation + example script</a></li>
  <li>NCI: <a href="https://opus.nci.org.au/display/Help/0.+Welcome+to+Gadi#id-0.WelcometoGadi-GadiJobs">Gadi Jobs</a></li>
  <li>Pawsey: <a href="https://support.pawsey.org.au/documentation/display/US/Job+Scheduling">Job scheduling</a>,
<a href="https://support.pawsey.org.au/documentation/display/US/Example+Job+Scripts">example scripts</a></li>
</ul>

<p>The above documentation also covers the special commands you’ll need to use to submit, cancel or check
the status of compute jobs, which will again be different between clusters.</p>

<p>RCC systems allow you to run as many jobs as you like (as long as you don’t overwhelm the cluster), but
computational jobs on the NCI or Pawsey systems are billed against your project’s <em>allocation</em>. Each
project is given a budget of a certain number of <em>service units</em> (SUs), which represent the amount of
resources and time a project is allowed to use in a quarter (i.e. three months), and are shared between
all members of a project. Whenever anyone in the project runs a job, an amount of service units are
deducted from the project’s budget, which can be checked by running <code class="language-plaintext highlighter-rouge">nci_account</code> on Gadi or
<code class="language-plaintext highlighter-rouge">pawseyAccountBalance</code> on Magnus.</p>

<p>Regardless of the underlying job scheduler, you should <em>never</em> run large computational jobs such as
simulations or compiling large codebases on the login nodes. Anything which may take more than a few
minutes or use more than a few GB of RAM should be run as a compute job via the scheduler. The login 
nodes are shared between all users and do not have very much computational power, so running a large job
on the login node will slow down or even crash other users’ sessions. This is a surefire way to get a 
cranky email from the system administrators, and may even result in your account being suspended. Don’t
run on the login node; use the scheduler.</p>

<h2 id="software-module-system">Software module system</h2>
<p>Users of an HPC system often require specific versions of software for their workflows, while some
software packages clash and cannot be used at the same time (for example, a particular program might
compile with version <em>X</em> of a compiler, but not version <em>X+1</em>).</p>

<p>Instead of making every version of every program available to all users at all times, clusters instead 
use <em>modules</em> to allow you to pick and choose which software to use at a given time. Typically, a
cluster will make a very limited set of essential programs available by default, with more specialised
software such as compilers or simulation software available as optional modules.</p>

<p>To load a module (and thus make the program it contains available to use), run the command 
<code class="language-plaintext highlighter-rouge">module load &lt;module_name&gt;</code> where <code class="language-plaintext highlighter-rouge">module_name</code> is the name of the <em>module file</em> to load. 
A module’s name usually has the form <code class="language-plaintext highlighter-rouge">&lt;program&gt;/&lt;version&gt;</code>, so to load version
2.14 of the program NAMD, you would do <code class="language-plaintext highlighter-rouge">module load namd/2.14</code>. To unload a module file, run <code class="language-plaintext highlighter-rouge">module
unload &lt;module_name&gt;</code>, while <code class="language-plaintext highlighter-rouge">module swap &lt;module1&gt; &lt;module2&gt;</code> will unload <code class="language-plaintext highlighter-rouge">module1</code> and load <code class="language-plaintext highlighter-rouge">module2</code>
in its place.</p>

<p>To list the modules available on the
system, run <code class="language-plaintext highlighter-rouge">module avail</code>, while running <code class="language-plaintext highlighter-rouge">module avail &lt;module&gt;</code> will list all available versions of a
specific module. If you’re not sure which module contains the program you’re interested in (or if the
program is even installed), you can run <code class="language-plaintext highlighter-rouge">module search &lt;query&gt;</code>, which will search
for any modules whose name or description matches a given query. Alternatively, you may want to only 
list the modules which you have loaded, which can be achieved by running <code class="language-plaintext highlighter-rouge">module list</code>.</p>

<p>Sometimes it’s not obvious what a module actually <em>does</em> or what software it provides. The command
<code class="language-plaintext highlighter-rouge">module show &lt;module_name&gt;</code> displays information about a given module, including programs and libraries
it provides.</p>

<h2 id="transferring-files-to-and-from-remote-servers">Transferring files to and from remote servers</h2>
<p>At some point, you’ll want to transfer files between the cluster and your computer. The easiest way to
do this is through an <em>SFTP</em> (<em>Secure File Transfer Protocol</em>) program running on your computer (not on
the cluster), which starts a connection between your computer and the cluster and allows you to
interactively select files to transfer back and forth.</p>

<p>There are both command-line and graphical SFTP programs; both are fine and it’s up to you which you
prefer to use. For Mac, the easiest to use graphical SFTP program is <a href="https://cyberduck.io/">Cyberduck</a>,
while for Windows the easiest is <a href="https://winscp.net/eng/index.php">WinSCP</a>. There is no graphical SFTP
program which is available on all Linux distributions, but if you’re using Ubuntu then a good option is
<a href="https://github.com/masneyb/gftp">gFTP</a>, which should be available in the Software Centre.</p>

<p>For all of the above programs, you’ll
need to make a new connection to the cluster before you can start using them: in Cyberduck this is
achieved by clicking the “New Connection” button in the main window, while WinSCP will automatically
launch a wizard to do this when you start it. Make sure to select “SFTP” as the “File Protocol”, then
enter the cluster’s address under “Host Name”, then enter your username and password. For example, if
your username is <code class="language-plaintext highlighter-rouge">jsmith</code> and you want to transfer files to or from Magnus, you would enter
<code class="language-plaintext highlighter-rouge">magnus.pawsey.org.au</code> as the Host Name and <code class="language-plaintext highlighter-rouge">jsmith</code> as the username.</p>

<p>The command-line program <code class="language-plaintext highlighter-rouge">sftp</code> is almost universally available, and only slightly-less user-friendly
than the graphical programs. Mac and Windows both have command-line clients which function the same way;
on Mac the command is <code class="language-plaintext highlighter-rouge">sftp</code>, while on Windows it is invoked as <code class="language-plaintext highlighter-rouge">sftp.exe</code>. Connecting to a server is
very similar to SSH - run the command <code class="language-plaintext highlighter-rouge">sftp &lt;username@cluster.address&gt;</code> in a new terminal window (or
<code class="language-plaintext highlighter-rouge">sftp.exe &lt;username@cluster.address&gt;</code> if using Windows) and enter your password when prompted. You can
move around and explore the cluster’s file system with the same commands you’d use in an SSH session
(<code class="language-plaintext highlighter-rouge">cd</code>, <code class="language-plaintext highlighter-rouge">ls</code>, etc), and can navigate your personal (or <em>local</em>) computer’s file system by using the same
commands prefaced with an “l” (<code class="language-plaintext highlighter-rouge">lcd</code>, <code class="language-plaintext highlighter-rouge">lls</code>, etc). To transfer files from the cluster to your computer, 
run <code class="language-plaintext highlighter-rouge">get &lt;file&gt;</code>. To transfer files from your computer to the cluster, run <code class="language-plaintext highlighter-rouge">put &lt;file&gt;</code>. In both cases,
<code class="language-plaintext highlighter-rouge">&lt;file&gt;</code> can either be a bare filename, in which case <code class="language-plaintext highlighter-rouge">sftp</code> will transfer from the current working
directory (on either the cluster or your computer, depending on whether you are using <code class="language-plaintext highlighter-rouge">put</code> or <code class="language-plaintext highlighter-rouge">get</code>),
or you can specify the full path to the file. <code class="language-plaintext highlighter-rouge">sftp</code> also supports tab-completion for both commands and
file names/paths.</p>

<h2 id="some-useful-commands">Some useful commands</h2>
<p>Finally, here are some useful commands, tips and tricks that didn’t quite fit elsewhere in this guide:</p>

<ul>
  <li>
    <p>Wildcards: Wildcards are a useful shell construct which allows you to access or manipulate multiple
files at once through <em>pattern matching</em>. Wildcards are represented by certain special characters, the
most common of which are “*”, which matches zero or more of any character, and “?” which matches
exactly one character. This is best demonstrated through examples.</p>

    <p>Let’s say we wanted to remove all <em>log files</em> in the current directory, which are created by programs
to keep details of their execution; they’re useful for debugging, but we may not need them once we’ve
generated the data. Log files generally end with the suffix <code class="language-plaintext highlighter-rouge">.log</code>, examples might be <code class="language-plaintext highlighter-rouge">CH4.log</code>, 
<code class="language-plaintext highlighter-rouge">C2H6.log</code> and so on. Instead of manually typing in all file names like <code class="language-plaintext highlighter-rouge">rm CH4.log C2H6.log C3H8.log</code>,
we can use a wildcard <code class="language-plaintext highlighter-rouge">*.log</code>, which will match all files whose name ends in the characters <code class="language-plaintext highlighter-rouge">.log</code>. So
the command <code class="language-plaintext highlighter-rouge">rm *.log</code> tells the shell to enumerate all files which end in <code class="language-plaintext highlighter-rouge">.log</code> and pass them to the
command <code class="language-plaintext highlighter-rouge">rm</code>. We aren’t aren’t just limited to whole words, either. If we had a set of log files whose
names have the form “<YEAR>-<MONTH>-<DAY>.log" (for example, the date on which they were generated), 
we could list all files from 2020 by doing `ls 2020-??-??.log` (remember that `?` matches exactly
one character, so files like "2020-full.log" won't be affected by this).</DAY></MONTH></YEAR></p>

    <p>Wildcards can be used for any command which requires a filename or path, and can greatly reduce the
amount of typing needed to select large numbers of files for a particular operation. The only caveat
is that the shell won’t warn you if you write a wildcard which catches files you didn’t intend it to,
so there is always a danger of accidentally deleting important files. Consequently, if you’re using
wildcards for a destructive operation (like <code class="language-plaintext highlighter-rouge">rm</code>-ing files), it’s a good idea to test which files the
wildcard matches with <code class="language-plaintext highlighter-rouge">ls</code> and check that it’s what you expected (i.e. before you do <code class="language-plaintext highlighter-rouge">rm *.out*</code>, run
<code class="language-plaintext highlighter-rouge">ls *.o*</code> and check that you haven’t caught anything you don’t want to delete).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">find</code>: as its name might suggest, <code class="language-plaintext highlighter-rouge">find</code> finds files in the filesystem (try saying that five times
fast). The syntax of <code class="language-plaintext highlighter-rouge">find</code> is somewhat intricate, but the basic usage requires you to specify a
starting directory and the criteria to search for; <code class="language-plaintext highlighter-rouge">find</code> then searches recursively “down” from the
starting point and prints any files which match the search criteria. The recursive searching is what
separates it from a tool like <code class="language-plaintext highlighter-rouge">ls</code>, which only lists files in a single directory.</p>

    <p>For example, to find all files in the current directory <em>and</em> its children with the suffix <code class="language-plaintext highlighter-rouge">.log</code> you
would type <code class="language-plaintext highlighter-rouge">find . -name "*.log"</code>: <code class="language-plaintext highlighter-rouge">.</code> is the target directory, <code class="language-plaintext highlighter-rouge">-name</code> tells <code class="language-plaintext highlighter-rouge">find</code> to match
filenames, and <code class="language-plaintext highlighter-rouge">*.log</code> is a wildcard pattern which matches any file name ending in “.log”.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">grep</code>: searches the contents of a file (or files) and prints all lines containing a particular 
pattern. Think of it like a command-line version of using <code class="language-plaintext highlighter-rouge">ctrl+f</code> to search a document in a word
processor. In its most basic usage, <code class="language-plaintext highlighter-rouge">grep</code> accepts a pattern to search for, and a list of files to
search through (which could also be a wildcard), so to search for the string “Temperature” in the file
“output.txt” you would do <code class="language-plaintext highlighter-rouge">grep Temperature output.txt</code>. By default, <code class="language-plaintext highlighter-rouge">grep</code> only searches for <em>exact</em>
matches to the specified pattern and is case-sensitive, so <code class="language-plaintext highlighter-rouge">grep Temperature &lt;file&gt;</code> will not match 
the string “temperature”.</p>

    <p><code class="language-plaintext highlighter-rouge">grep</code> supports a plethora of command-line options, so be sure to check out the man page if you need
to do something complicated (do <code class="language-plaintext highlighter-rouge">man grep</code>), but some useful ones are:</p>
    <ul>
      <li><code class="language-plaintext highlighter-rouge">-n</code>: print the line in the file in which a match occurs, as well as the match.</li>
      <li><code class="language-plaintext highlighter-rouge">-i</code>: ignore case when matching strings, so “Temperature” and “temperature” would match, for
example.</li>
      <li><code class="language-plaintext highlighter-rouge">-v</code>: invert match, so only lines <em>not</em> containing the specified pattern will be printed.</li>
      <li><code class="language-plaintext highlighter-rouge">-A &lt;num&gt;</code>, <code class="language-plaintext highlighter-rouge">-B &lt;num&gt;</code>: print <code class="language-plaintext highlighter-rouge">&lt;num&gt;</code> lines <em>A</em>fter or <em>B</em>efore matching lines. By default, <code class="language-plaintext highlighter-rouge">grep</code>
will only print the contents of lines containing matches; with these options it prints the
surrounding lines (before or after) each match to give context for the matches.</li>
      <li><code class="language-plaintext highlighter-rouge">-o</code>: only print the matches, not the lines containing them.</li>
      <li><code class="language-plaintext highlighter-rouge">-w</code>: only print matches which are a whole word, rather than matching all substrings. For example,
this would mean that <code class="language-plaintext highlighter-rouge">grep -w bash</code> only matches the the complete word “bash” and would not match
“bashrc”, for example.</li>
      <li><code class="language-plaintext highlighter-rouge">-x</code> (or <code class="language-plaintext highlighter-rouge">--line-regexp</code>): like <code class="language-plaintext highlighter-rouge">-w</code>, but only print matches which are a whole line.</li>
    </ul>

    <p>In addition to plain text, <code class="language-plaintext highlighter-rouge">grep</code> also supports matching against <em>regular expressions</em> (often
shortened to <em>regex</em>), which are like wildcards, but with much richer functionality. There is not 
enough space in this guide to explain regular expressions in any level of depth; check out <a href="https://www.grymoire.com/Unix/Regular.html">this 
guide</a> if you’re interested.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">tee &lt;file&gt;</code>: prints its input to both standard output <em>and</em> a specified file. <code class="language-plaintext highlighter-rouge">tee</code> is almost always
used as part of a pipeline where you want to see the output of a command and also save it to a file
for later: e.g. <code class="language-plaintext highlighter-rouge">./prog | tee output.txt</code>.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">echo &lt;string&gt;</code>: prints a string to the terminal. For example, <code class="language-plaintext highlighter-rouge">echo "Hello, World!"</code> prints “Hello,
World!” to the terminal. This is mostly useful for printing status updates from a script (e.g. <code class="language-plaintext highlighter-rouge">echo
"Removing log files..."</code>).</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">wc &lt;file&gt;</code> (short for “word count”): counts the lines, words and characters in a file (or group of
files) and prints the counts to the terminal. By default, <code class="language-plaintext highlighter-rouge">wc</code> outputs one line per file of the form:
<code class="language-plaintext highlighter-rouge">&lt;num_lines&gt; &lt;num_words&gt; &lt;num_characters&gt; &lt;filename&gt;</code>, 
with an extra line for the total counts if more than one file is processed. The output format can be
changed by passing the <code class="language-plaintext highlighter-rouge">-l</code> (only count the number of lines), <code class="language-plaintext highlighter-rouge">-w</code> (only count the words), <code class="language-plaintext highlighter-rouge">-m</code> (only
count the characters). If no files are specified, <code class="language-plaintext highlighter-rouge">wc</code> will operate on standard input (i.e. typing in
words manually) and can be used in pipelines.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">sort</code>: sorts a stream of text data supplied either from standard input or a file. <code class="language-plaintext highlighter-rouge">sort</code> can handle 
alphabetical, numerical (via the <code class="language-plaintext highlighter-rouge">-n</code> flag) or general floating point (<code class="language-plaintext highlighter-rouge">-g</code>) data, and it is possible
to select which column to sort by via the <code class="language-plaintext highlighter-rouge">-k</code> flag. The column separator can be set via the
<code class="language-plaintext highlighter-rouge">--field-separator=&lt;sep&gt;</code> option, in the case of multiple-column input like a CSV file (where <code class="language-plaintext highlighter-rouge">sep</code>
would be “,”).</p>
  </li>
  <li>
    <p>Bash variables: it’s possible to declare a variable in bash via the syntax <code class="language-plaintext highlighter-rouge">&lt;variable&gt;=&lt;value&gt;</code>, where
<code class="language-plaintext highlighter-rouge">&lt;value&gt;</code> is any arbitrary string. Variables can be used to store and manipulate values to be used
later in a script or interactive session. Their names can contain letters, underscores and numbers
(importantly, not hyphens or asterisks), but cannot start with a number.</p>

    <p>There are two important notes on the syntax of variable assignment. First the lack of space between
the variable name and the “=” is significant, since bash will interpret the variable name as a command
(and probably fail, since it does not exist yet) if there is a space (i.e. <code class="language-plaintext highlighter-rouge">variable = value</code>).
Second, even though you can enter anything you like, bash will treat everything that’s not a command 
as a string, so numerical values have no special significance to bash (they may have significance when
passed to certain commands like <code class="language-plaintext highlighter-rouge">sort</code> which <em>do</em> handle numerical values). By convention, shell
variable names are written in UPPER CASE, although this is not a technical requirement.</p>

    <p>Variables are referenced by prepending their name with a “$”, e.g. <code class="language-plaintext highlighter-rouge">$variable</code>, which will cause bash
to substitute the variable’s value in place of its reference. For example, if we have a variable
<code class="language-plaintext highlighter-rouge">OUTPUT_FILE=output.txt</code> we can redirect a program’s output to it by <code class="language-plaintext highlighter-rouge">./prog &gt; $OUTPUT_FILE</code>. You can
also use the value of a variable inside a string, such as a filename, by encasing the variable in
curly-braces “${“ and “}” (you still need the “$” in front), so if you wanted to make a filename based
on the value of the variable <code class="language-plaintext highlighter-rouge">RUN_NUMBER</code> you could type something like <code class="language-plaintext highlighter-rouge">./prog &gt; ${RUN_NUMBER}.txt</code>.</p>

    <p>Additionally, many programs read from shell variables to determine their run-time behaviour. For
example, programs using the OpenMP parallel programming framework (including LAMMPS and VASP) check
the value of the variable <code class="language-plaintext highlighter-rouge">OMP_NUM_THREADS</code> to determine how many CPU cores to use in the calculation.
In order for the value of a variable to be visible to any programs you run, it needs to be <em>exported</em>,
which is most easily achieved by putting the keyword “export” in front of its declaration; instead of
writing <code class="language-plaintext highlighter-rouge">OMP_NUM_THREADS=8</code> you would write <code class="language-plaintext highlighter-rouge">export OMP_NUM_THREADS=8</code>.</p>
  </li>
  <li>
    <p><code class="language-plaintext highlighter-rouge">~/.bashrc</code> and aliases: you can configure bash and have it store variables and settings across
sessions by modifying a file named <code class="language-plaintext highlighter-rouge">~/.bashrc</code>. Bash will execute all commands in <code class="language-plaintext highlighter-rouge">~/.bashrc</code> 
(including setting and exporting variables) at the start of each new shell session (e.g. logging in 
via SSH). There will be a specially-tuned default <code class="language-plaintext highlighter-rouge">~/.bashrc</code> file on the clusters, so it’s best to 
add new commands and configuration options <em>after</em> any pre-existing lines.</p>

    <p>There are a few general-purpose things you can add to your <code class="language-plaintext highlighter-rouge">~/.bashrc</code> to tailor the shell to your 
needs. The biggest
of these are <em>aliases</em>, which allow you to create your own shortcuts for complicated shell commands.
Aliases take the form <code class="language-plaintext highlighter-rouge">alias &lt;new&gt;="&lt;old&gt;"</code>, where <code class="language-plaintext highlighter-rouge">new</code> is the shortcut you wish to create and <code class="language-plaintext highlighter-rouge">old</code> 
is the original command (<code class="language-plaintext highlighter-rouge">old</code> must be encased in quotes). For example, if you regularly use <code class="language-plaintext highlighter-rouge">grep</code> 
with the <code class="language-plaintext highlighter-rouge">-n</code> option, you could add <code class="language-plaintext highlighter-rouge">alias grepn="grep -n"</code> to your <code class="language-plaintext highlighter-rouge">~/.bashrc</code>, so whenever you run
<code class="language-plaintext highlighter-rouge">grepn</code> the shell will automatically execute <code class="language-plaintext highlighter-rouge">grep -n</code> instead. Aliases must be stored in <code class="language-plaintext highlighter-rouge">~/.bashrc</code>
if you want to keep them active for all bash sessions; it’s possible to interactively define aliases
as your using bash, but they will disappear when you exit the shell and won’t be available in other
terminal windows if you don’t save them.</p>

    <p>Finally, once you’ve made changes to your <code class="language-plaintext highlighter-rouge">.bashrc</code>, you’ll need to either reload bash (by starting a
new terminal window, for example) or run <code class="language-plaintext highlighter-rouge">source ~/.bashrc</code> for the changes to take effect.</p>
  </li>
  <li>
    <p>Easier SSH and SFTP logins for Mac and Linux: to save having to memorise and type out the 
username+address combination for every cluster you use, it’s useful to save the various addresses in 
the <code class="language-plaintext highlighter-rouge">.bashrc</code> on your personal computer. The best way to do this is by adding a line exporting the 
username+address as an environment variable, such as <code class="language-plaintext highlighter-rouge">export tinaroo="username@tinaroo.rcc.uq.edu.au"</code>
(note the quotation marks). This would then allow you to log in to Tinaroo by doing <code class="language-plaintext highlighter-rouge">ssh $tinaroo</code> and
to get files by doing <code class="language-plaintext highlighter-rouge">sftp $tinaroo</code>. It’s a good idea to do this for all clusters you have access
to, with each cluster getting its own variable on its own line in the <code class="language-plaintext highlighter-rouge">.bashrc</code> file.</p>
  </li>
</ul>

<h2 id="test-your-knowledge">Test your knowledge</h2>
<p>One of the greatest demonstrations of the power of the UNIX shell came in the form of <a href="https://leancrew.com/all-this/2011/12/more-shell-less-egg/">dueling magazine 
columns between two prominent computer scientists in the 
1980s</a>. A problem was posed to Don Knuth (a
founder of the field of academic computer science) and Doug McIlroy (one of the original developers of 
the UNIX operating system): Read a file of text, determine the n most frequently used words, and print
out a sorted list of those words along with their frequencies. Knuth developed an incredibly intricate,
10+ page long program from scratch, while McIlroy did the same in a six-command shell pipeline. The
solution, and McIlroy’s explanation are reproduced below:</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>tr -cs A-Za-z '\n' | tr A-Z a-z | sort | uniq -c | sort -rn | sed ${1}q
</code></pre></div></div>

<blockquote>
  <p>If you are not a UNIX adept, you may need a little explanation, but not much, to understand this pipeline of processes. The plan is easy:</p>

  <p>1) Make one-word lines by transliterating the complement (-c) of the alphabet into newlines (note the quoted newline), and squeezing out (-s) multiple newlines.</p>

  <p>2) Transliterate upper case to lower case.</p>

  <p>3) Sort to bring identical words together.</p>

  <p>4) Replace each run of duplicate words with a single representative and include a count (-c).</p>

  <p>5) Sort in reverse (-r) numeric (-n) order.</p>

  <p>6) Pass through a stream editor; quit (q) after printing the number of lines designated by the script’s first parameter (${1}).</p>
</blockquote>

<p>Playing with this pipeline is a great way to internalise the essential logic of the command line. What
follows is a small set of guided problems based on the above pipeline that will help you cement your
understanding of the Linux command line.</p>

<h3 id="generating-the-input-text">Generating the input text</h3>
<p>Before we can use our pipeline, we need to generate a set of input text to test it on. Let’s use the
manual/information page for bash. First, try running <code class="language-plaintext highlighter-rouge">info bash</code> in the command line.</p>

<p><strong>Q)</strong> Why will this output not work in our pipeline?</p>

<p><strong>A)</strong> Because it is piping the output through a pager (on my computer it uses the antiquated <code class="language-plaintext highlighter-rouge">more</code>, which
is like <code class="language-plaintext highlighter-rouge">less</code> but with fewer features), not <code class="language-plaintext highlighter-rouge">stdout</code>. Since the output is already being consumed by a
program, putting <code class="language-plaintext highlighter-rouge">info bash</code> in a pipeline as is will not do us any good, since there will be nothing
for the next program to consume.</p>

<p>We will therefore need to tell <code class="language-plaintext highlighter-rouge">info</code> to print to standard output, without piping through <code class="language-plaintext highlighter-rouge">more</code>. We
also need to tell it to print every “bash” info page at once, rather than paging through them. This
is achieved by passing the <code class="language-plaintext highlighter-rouge">-a</code> and <code class="language-plaintext highlighter-rouge">-o -</code> options to info. Try running <code class="language-plaintext highlighter-rouge">info bash -a -o -</code> on your 
command line and observe the difference.</p>

<h3 id="transliterating">Transliterating</h3>
<p>The next command in our pipeline is <code class="language-plaintext highlighter-rouge">tr</code>, which stands for “translate” or “transliterate”. It’s used to
essentially swap certain characters, or sets of characters, with another set of characters, such as when
translating some file to all upper- or lower-case. In this case, we want to use <code class="language-plaintext highlighter-rouge">tr</code> twice.</p>

<p>The first instance removes all instances of non-alphabetical characters and replaces them with a
<em>newline</em> - a special character which inserts a line-break into the output (equivalent to pressing the
“enter” key in a text editor or word-processor). This has the effect of separating out words and
printing them on separate lines (since whitespace is non-alphabetical), as well as removing any 
numbers or special characters (like “-“ or “:”).
The second invocation of <code class="language-plaintext highlighter-rouge">tr</code> replaces all upper-case characters (<code class="language-plaintext highlighter-rouge">A-Z</code>) with their lower-case
equivalents (<code class="language-plaintext highlighter-rouge">a-z</code>), to ensure that words are not double-counted due to capitalisation (e.g.
“Interpreted” and “interpreted” should be counted as a single word).</p>

<h3 id="putting-it-all-in-a-script">Putting it all in a script</h3>
<p>Now we’re ready to put our pipeline into a shell script to make it easier to use.</p>

<p><strong>Q)</strong> Use the information in the “Automate common tasks” section to make an executable shell script to
hold your modified pipeline. Give it a descriptive name like <code class="language-plaintext highlighter-rouge">word_historgram.sh</code>.</p>

<p>Now, you may notice that there’s one part of the pipeline that we haven’t discussed: <code class="language-plaintext highlighter-rouge">sed ${1}q</code>. First,
<code class="language-plaintext highlighter-rouge">sed &lt;num&gt;q</code> prints the first <code class="language-plaintext highlighter-rouge">&lt;num&gt;</code> lines of its text input. It’s functionally the same as <code class="language-plaintext highlighter-rouge">head</code>, but
McIlroy used it in his solution because <code class="language-plaintext highlighter-rouge">head</code> hadn’t been written yet! You can replace <code class="language-plaintext highlighter-rouge">sed ${1}q</code>
with <code class="language-plaintext highlighter-rouge">head -n ${1}</code> if you like <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote">2</a></sup>.</p>

<p>text (either text files for <code class="language-plaintext highlighter-rouge">stdin</code>) and is one of the most powerful shell tools in Linux. The keen
  reader may appreciate going over <a href="https://www.grymoire.com/Unix/Sed.html">this unofficial
  documentation</a>.</p>

<p>Now let’s talk about <code class="language-plaintext highlighter-rouge">${1}</code>. Numbered shell variables store the arguments which were passed to the shell 
script when launched. The first argument is stored in <code class="language-plaintext highlighter-rouge">$1</code>, the second is stored in <code class="language-plaintext highlighter-rouge">$2</code> and so on, so
if we call our script with <code class="language-plaintext highlighter-rouge">word_histogram.sh 10</code>, then <code class="language-plaintext highlighter-rouge">${1}</code> will have the value of <code class="language-plaintext highlighter-rouge">10</code>, and <code class="language-plaintext highlighter-rouge">sed</code>
will print the first 10 lines of the sorted list.</p>

<p><strong>Q)</strong> What are the 12 most frequently used words in the bash information page?</p>

<h3 id="find-the-frequency-of-a-specific-word">Find the frequency of a specific word</h3>
<p>Finally, it might be useful to be able to specify a particular word and find its frequency in the info
pages. We can do this using <code class="language-plaintext highlighter-rouge">grep</code>, with the <code class="language-plaintext highlighter-rouge">-o</code> flag to print just the matching word (as opposed to
the whole line, which is the default behaviour). It may also be useful to invoke <code class="language-plaintext highlighter-rouge">grep</code> with the <code class="language-plaintext highlighter-rouge">-i</code>
flag, which tells it to ignore case when finding matches.</p>

<p><strong>Q)</strong> Modify your script so that it can take a word as input and count the number of times this word
appears in the text. Compare the results to the original histogram pipeline for the word “shell”. What
are some reasons it might give different answers? Is there a shorter way to achieve this than a simple
substitution into the original pipeline?</p>

<p><strong>A)</strong> As we have invoked it, <code class="language-plaintext highlighter-rouge">grep</code> will match <em>sub-strings</em>, as well as whole words; <code class="language-plaintext highlighter-rouge">grep -i "shell"</code>
will match both “shell” and “subshell”. This is not the case for the <code class="language-plaintext highlighter-rouge">tr</code>-pipeline, which <em>does</em> only
count whole words. We can fix this by passing <code class="language-plaintext highlighter-rouge">-w</code> to <code class="language-plaintext highlighter-rouge">grep</code>, which tells it to only match whole words.</p>

<h2 id="resources-and-further-reading">Resources and further reading</h2>
<p>Once you’re up and running on the clusters, you may want to check out the <em>Software Carpentry</em> workshops
on the Unix shell: there’s a tutorial on <a href="https://swcarpentry.github.io/shell-novice/">the basics</a> and 
a follow-up <a href="https://carpentries-incubator.github.io/shell-extras/">advanced course</a> (which is currently
only partially finished). You can either skim over the tutorials and work through specific sections as 
you need them, or do the course all in one go (Software Carpentry estimates that both workshops can be
completed in a few hours).</p>

<p>In particular, it’s worth looking over the module on 
<a href="https://swcarpentry.github.io/shell-novice/04-pipefilter/index.html">pipes</a> and taking time to do the
example problems.</p>

<p>Some other resources you may find useful:</p>

<ul>
  <li><a href="https://learnxinyminutes.com/docs/bash/">Learn bash in Y minutes</a>: covers similar material to the
Software Carpentry workshops, but is structured more like a reference manual than a tutorial. It’s
quite terse, so it’s faster to work through than Software Carpentry, but requires more “reading
between the lines” to get the most out of it.</li>
  <li><em>Mastering Linux Shell Scripting: A practical guide to Linux command-line, Bash scripting, and Shell
programming</em>. This is a more long-form introduction to Linux shell scripting. It’s useful as a 
learning resource with worked examples, and is available as an eBook through many university libraries.</li>
  <li><a href="https://devhints.io/bash">devhints bash cheat sheet</a>: concise, comprehensive reference guide to bash
syntax and concepts. Extremely useful for when you need to look up something you’ve forgotten how to
do.</li>
  <li><a href="https://www.grymoire.com/Unix/">Bruce Barnett’s UNIX tutorials</a>: somewhat old but still useful
tutorials dealing with “UNIX shell programming and various other arcane subjects of interest to
wizards”. Covers many useful utilities and lesser known bash tricks.</li>
</ul>
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>From the memo by Douglas McIllroy proposing the addition of pipes to (original) Unix: <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p><code class="language-plaintext highlighter-rouge">sed</code> (stands for “stream editor”) is a utility to programmatically manipulate and edit streams of <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">CTCMS Documentation and Tutorials</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">CTCMS Documentation and Tutorials</li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list"><li><a href="https://github.com/CTCMS-UQ"><svg class="svg-icon"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg> <span class="username">CTCMS-UQ</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>This is the online home of documentation written by and for members of the Centre for Computational and Theoretical Molecular Science (CTCMS) at the University of Queensland. Currently, it is intended to be used for computing tutorials - Linux, scientific programming, debugging, etc.
</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
